{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a86abe-7cfa-4861-bce5-1bb0c358a708",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Sell Side Recommendation Model\n",
    "\n",
    "Build a classification model that replaces the sell-side equity analyst team covering \n",
    "a particular stock or index\n",
    "\n",
    "* Output a buy, sell, or hold reccomendation by producing a model that shows \n",
    "the projected price vs. the street consensus (average of the major wall street bank \n",
    "price targets vs. our price target)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502dbce9-11b7-4fd9-ba9e-3c9d7cefec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Look at a variety of factors that could potentially predict the price action\n",
    "of the stock:\n",
    "* Macro: Yield curve, interest rates \n",
    "* Fundamental: EBITDA, EPS, revenue\n",
    "* Technical: Closing prices, moving averages, VWAP\n",
    "* Sentiment: Sentiment analysis thru NLP \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59330e7-0949-4529-a737-26d9de86e7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ML MODELS WE WILL USE\n",
    "* random forests\n",
    "* logistic regression\n",
    "* neural network \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c88f687-280d-420f-9471-19bb43e5e229",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"If the backtested model shows that the stock will move in a certain way, we will use a linear regression\n",
    "of the price to report the anticipated price action (mix of both quantitative and qualitative factors)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0757be72-4923-4b59-9e24-601394838bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Finally, incorporate a UI through Streamlit\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37090c21-ed98-47e9-a620-00b0aed72a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Neural Network using these factors to create a multi-classification model\n",
    "# to determine buy, sell, or hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53f93c17-f233-4e8d-a868-2b60854c462e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26536\\3757499517.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_current_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"keras\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m     \u001b[0m_keras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;34m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# Import the target module and insert it into the parent's namespace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_module_globals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_local_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\api\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_wrapper\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\api\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\api\\keras\\datasets\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcifar100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfashion_mnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mpath_stats\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "089770b9-123e-473d-8367-ddc1185d7bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_B</th>\n",
       "      <th>_H</th>\n",
       "      <th>_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _B  _H  _S\n",
       "0   1   0   0\n",
       "1   0   1   0\n",
       "2   0   1   0\n",
       "3   0   0   1\n",
       "4   0   0   1\n",
       "5   1   0   0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "target = pd.DataFrame(['B', 'H', 'H', 'S', 'S', 'B'])\n",
    "pd.get_dummies(target, prefix = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a609396-e225-4e8f-8fdf-e97e0d3ef9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the applicants_data.csv file from the Resources folder into a Pandas DataFrame\n",
    "applicant_data_df = df = pd.read_csv(\n",
    "    Path(\"Resources/applicants_data.csv\")\n",
    ")\n",
    "\n",
    "\n",
    "# Review the DataFrame\n",
    "applicant_data_df\n",
    "\n",
    "\"\"\"FIT TO OUR DATASET ONCE WE HAVE DATA READY\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b577c9-894e-49ab-afd3-622ff3fe6bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the data types associated with the columns\n",
    "print(applicant_data_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb71c710-cd16-48bd-be28-2b15768d60b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'EIN' and 'NAME' columns from the DataFrame\n",
    "applicant_data_df = applicant_data_df.drop(columns = [\"EIN\", \"NAME\"])\n",
    "\n",
    "# Review the DataFrame\n",
    "applicant_data_df\n",
    "\n",
    "\"\"\"FIT TO OUR DATASET ONCE WE HAVE DATA READY\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6016809-6d03-4d98-a14f-c34db9fcb887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of categorical variables \n",
    "categorical_variables = applicant_data_df.select_dtypes(include = [\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "# Display the categorical variables list\n",
    "categorical_variables\n",
    "\n",
    "\"\"\"FIT TO OUR DATASET ONCE WE HAVE DATA READY\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c2834f-c046-40c6-a695-bf9d12bee8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse_output = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd19a69-3594-4b0a-aa29-138a74197666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorcal variables using OneHotEncoder\n",
    "encoded_data = enc.fit_transform(applicant_data_df[categorical_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e53080d-3e8f-4922-9fac-139f846fd239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the encoded variables\n",
    "encoded_df = pd.DataFrame(encoded_data, columns = enc.get_feature_names_out(categorical_variables))\n",
    "\n",
    "# Review the DataFrame\n",
    "encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ac2beb-a102-48e2-b246-16b30f5716ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the numerical variables from the original DataFrame to the one-hot encoding DataFrame\n",
    "numerical_variables = applicant_data_df.select_dtypes([\"int64\", \"float64\"])\n",
    "encoded_df = pd.concat([encoded_df, numerical_variables], axis = 1)\n",
    "\n",
    "# Review the Dataframe\n",
    "encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0697cb-209b-4558-a44a-0b123e6fac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target set y using the IS_SUCCESSFUL column\n",
    "y = encoded_df[\"IS_SUCCESSFUL\"]\n",
    "\n",
    "# Display a sample of y\n",
    "y\n",
    "\n",
    "\"\"\"FIT TO OUR DATASET ONCE WE HAVE DATA READY\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64bbe27-726b-4699-8b3c-b17c79dd2c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features set X by selecting all columns but IS_SUCCESSFUL\n",
    "X = encoded_df.drop(columns = \"IS_SUCCESSFUL\")\n",
    "\n",
    "# Review the features DataFrame\n",
    "X\n",
    "\n",
    "\"\"\"FIT TO OUR DATASET ONCE WE HAVE DATA READY\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2d9c81-1999-4959-906a-cce7954940e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "# Assign the function a random_state equal to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81275e65-ca5c-45aa-9e9d-0a78f0e32001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411faf05-130c-4b6f-ac11-045d2719306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features = number_input_features = X_train_scaled.shape[1]\n",
    "\n",
    "# Review the number of features\n",
    "number_input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1278b0cb-08d3-4475-ac2a-afb3021d30d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of neurons in the output layer\n",
    "number_output_neurons = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28320141-f5bf-46cc-b1a8-097ca9466590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of hidden nodes for the second hidden layer\n",
    "hidden_nodes_layer2 = hidden_nodes_layer1 // 2\n",
    "\n",
    "# Review the number hidden nodes in the second layer\n",
    "hidden_nodes_layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269d5ed0-783c-4ea6-ba60-1f3c78ce71d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sequential model instance\n",
    "nn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac5280-a861-4dd0-b4f7-e5c5a1c26675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the first hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958b3a14-80c4-48b2-be87-0f2dae33e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the second hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fafea3-9c1e-4671-a1e9-144639015bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn.add(Dense(units=number_output_neurons, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5641a7db-2dff-4037-bd9a-1a21cfe6fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Sequential model summary\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b893782-5639-4a79-abb8-2994f3f8afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311a46f6-de65-4eeb-92b8-7e15868ff052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b45f790-944d-4e39-9ef7-4b47936a872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model's file path\n",
    "file_path = \"AlphabetSoup.h5\"\n",
    "\n",
    "# Export your model to a HDF5 file\n",
    "nn.save(file_path)\n",
    "\n",
    "\"\"\"FIT TO OUR DATASET ONCE WE HAVE DATA READY\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bd1fc1-c122-4396-beb9-e31df9f6aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e74f3f-1a68-449f-8664-24700c24074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features = len(X_train.iloc[0])\n",
    "\n",
    "# Review the number of features\n",
    "number_input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06662653-db17-4f3f-9085-62d0468901b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of neurons in the output layer\n",
    "number_output_neurons_A1 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7651cbe-65b9-47e2-9000-8b500e689178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of hidden nodes for the first hidden layer\n",
    "hidden_nodes_layer1_A1 = 20\n",
    "\n",
    "# Review the number of hidden nodes in the first layer\n",
    "hidden_nodes_layer1_A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4abca5-4d52-4e56-a877-16034d4aa455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sequential model instance\n",
    "nn_A1 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c761dc02-2770-4d8b-a340-b1a2828a9bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First hidden layer\n",
    "nn_A1.add(Dense(units=hidden_nodes_layer1_A1, input_dim=number_input_features, activation=\"softmax\"))\n",
    "\n",
    "# Output layer\n",
    "nn_A1.add(Dense(units= number_output_neurons_A1, activation=\"softmax\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_A1.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f7f8d0-af1d-48ca-bbe0-9f86dc6a6aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn_A1.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3bd8a4-723f-47c7-aa6b-b58384f0b6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "fit_model_A1 = nn.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bda4fc4-f824-43fc-a1b6-0c7239f9931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b35894c-5f75-4094-8c38-547df695785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features = len(X_train.iloc[0])\n",
    "\n",
    "# Review the number of features\n",
    "number_input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91526db-bfca-4eed-a195-a6bda51546c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of neurons in the output layer\n",
    "number_output_neurons_A2 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4b4fa0-0762-49b7-bbc2-eb1ab8dc1a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of hidden nodes for the first hidden layer\n",
    "hidden_nodes_layer1_A2 = 50\n",
    "\n",
    "# Review the number of hidden nodes in the first layer\n",
    "hidden_nodes_layer1_A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a632d9e-e105-47f5-bd8e-ffd758632c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sequential model instance\n",
    "nn_A2 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf3390-2e6f-43c1-a9c8-aa7f7b5df8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First hidden layer\n",
    "nn_A2.add(Dense(units=hidden_nodes_layer1_A2, input_dim=number_input_features, activation=\"softmax\"))\n",
    "\n",
    "# Output layer\n",
    "nn_A2.add(Dense(units= number_output_neurons_A1, activation=\"softmax\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_A2.summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc6e1dd-c64b-415a-a19c-d2c101064215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn_A2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f747f4-755e-40f6-8c43-73d77834eccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "fit_model_A2 = nn.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf09a5d4-ad31-4af0-8cae-0110e65a5f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the results of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e891a8-d369-448f-81eb-9fc57c51ae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Model Results\")\n",
    "\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318dcfcd-f192-48bc-a4dc-fc5ebf9cac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Alternative Model 1 Results\")\n",
    "\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn_A1.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd95f7ba-f112-4e3d-91a0-7321cd0a6a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Alternative Model 2 Results\")\n",
    "\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn_A2.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8443f9be-071c-42d6-81f8-8f684686e352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Results of Alternative Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6528fe34-132d-44dc-a70a-db4b0d2e4416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file path for the first alternative model\n",
    "file_path_A1 = \"AlternativeModel1.h5\"\n",
    "\n",
    "# Export your model to a HDF5 file\n",
    "nn_A1.save(file_path_A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dbd4e5-42a6-430e-881e-b65599da2273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file path for the first alternative model\n",
    "file_path_A2 = \"AlternativeModel2.h5\"\n",
    "\n",
    "# Export your model to a HDF5 file\n",
    "nn_A2.save(file_path_A2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
